# hadoop2-cluster-docker

## æ–°å¢hive
å®¹å™¨å¯åŠ¨åï¼Œéœ€è¦æ£€æŸ¥hiveå’Œhadoopä½¿ç”¨çš„guavaåŒ…çš„ç‰ˆæœ¬æ˜¯å¦ä¸€è‡´ï¼Œä¾‹å¦‚hiveä½¿ç”¨çš„guavaç‰ˆæœ¬é«˜äºhadoopä½¿ç”¨çš„guavaç‰ˆæœ¬ï¼Œé‚£ä¹ˆ`rm ${HADOOP_HOME}/share/hadoop/common/lib/guava-*.jar && cp ${HIVE_HOME}/lib/guava-*.jar ${HADOOP_HOME}/share/hadoop/common/lib/`

hiveå¯åŠ¨

é…ç½®
```
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://mysql:3306/yhy</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>yhy</value>
    <description>Username to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>my-secret-pw</value>
    <description>password to use against metastore database</description>
  </property>


# åœ¨viä¸­æ›¿æ¢å˜é‡
:%s#${system:java.io.tmpdir}#/tmp/javaiotmp#
:%s#${system:user.name}#root#

----- hadoop core-site.xml -----
    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>
    </property>
```

åˆå§‹åŒ–å…ƒæ•°æ®åº“ï¼š`schematool -initSchema -dbType mysql`

é€šè¿‡hiveserver2, éœ€è¦å°†hive-site.xmlæ–‡ä»¶ä¸­çš„hive.server2.thrift.bind.hostå±æ€§é…ç½®ä¸ºhadoop01
```Bash
$ hiveserver2                     # å¯åŠ¨hiveserver2æœåŠ¡
$ hive --service hiveserver2 &    # åå°å¯åŠ¨hiveserver2æœåŠ¡

$ bin/beeline -u jdbc:hive2://hadoop01:10000 -n root
```
é€šè¿‡metastore, éœ€è¦å°†hive-site.xmlæ–‡ä»¶ä¸­çš„hive.metastore.uriså±æ€§é…ç½®ä¸ºthrift://hadoop01:9083
```Bash
$ hive --service metastore &      # åå°å¯åŠ¨metastoreæœåŠ¡

$ bin/hive                        # è¿æ¥metastore
```
---
åˆ©ç”¨dockerå®¹å™¨æ¨¡æ‹Ÿhadoopé›†ç¾¤çš„éƒ¨ç½²ã€‚

ä½¿ç”¨æ­¥éª¤ï¼š

1. åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ”¾ç½®hadoop2çš„éƒ¨ç½²åŒ…ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå®˜æ–¹åŒ…åä¸º hadoop-x.x.x.tar.gz, å…¶ä¸­xxxä¸ºç‰ˆæœ¬å·
2. ä½¿ç”¨è„šæœ¬`build.sh`æ„å»ºé•œåƒï¼Œè„šæœ¬å†…éƒ¨çš„å‘½ä»¤`docker build -t hadoop2 --build-arg HADOOP_PACKAGE=hadoop-x.x.x .` æ„å»ºä¸€ä¸ªåä¸ºhadoop2çš„é•œåƒï¼Œæ­¤å¤„è®°å¾—å°†ç‰ˆæœ¬å·æ¢æˆè‡ªå·±æ‰€ç”¨çš„hadoopç‰ˆæœ¬å·ï¼›
3. ä¿®æ”¹etc-hadoopæ–‡ä»¶å¤¹ä¸‹çš„é…ç½®æ–‡ä»¶;
4. ä½¿ç”¨`docker-compose up` å¯åŠ¨hadoopå®¹å™¨é›†ç¾¤ï¼›

å…³äºhadoopå®¹å™¨é›†ç¾¤çš„è§„åˆ’åœ¨æ–‡ä»¶docker-compose.ymlä¸­:
- hadoop-01: NameNode, DataNode, NodeManager, ResourceManager, JobHistoryServer
- hadoop-02: SecondaryNameNode, DataNode, NodeManager
- hadoop-03: DataNode, NodeManager

## å½“å‰é…ç½®
```
# ----- core-site.xml ----
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop01/</value>
    </property>
</configuration>

# ----- hdfs-site.xml ----
<configuration>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop01:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop02:50090</value>
    </property>
</configuration>

# ----- yarn-site.xml -----
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop01</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>

# ----- mapred-site.xml -----
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

# ----- hadoop-env.sh -----
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/hadoop

# ----- slaves -----
hadoop01
hadoop02
hadoop03
```

æŒ‰ç…§å¦‚ä¸Šè§„åˆ’ï¼Œæ¥ä¸‹æ¥åº”è¯¥ï¼š
1. åœ¨hadoop-01ä¸Šæ‰§è¡Œ`hdfs namenode -format`ï¼›
2. åœ¨hadoop-01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`./start-dfs.sh`ï¼›
3. åœ¨hadoop-01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`./start-yarn.sh`ï¼›
4. åœ¨hadoop-01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`./mr-jobhistory-daemon.sh start historyserver`ï¼›

æ¥ä¸‹æ¥å¼€å§‹æ„‰å¿«çš„hadoopä¹‹æ—…å§ï¼ğŸ˜
